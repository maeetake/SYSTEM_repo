{
    "tasks": [
        {
            "task_name": "Load User-Provided Data",
            "description": "This initial task involves loading the historical NVIDIA stock data from a user-provided CSV file. This data is the foundation for all subsequent steps, including preprocessing, training, and evaluation. The expected outcome is a Pandas DataFrame containing the raw stock data.",
            "dependencies": [],
            "constraints": [
                "The sole data source must be the user-provided CSV file; external APIs or data sources are prohibited.",
                "The CSV file must contain columns for 'Date', 'Open', 'High', 'Low', and 'Close' covering the last 5.5 years."
            ]
        },
        {
            "task_name": "Preprocess Data",
            "description": "This task cleans and transforms the raw data into a format suitable for time series modeling. It involves handling missing values, normalizing features to a consistent scale, and creating sequential data windows. Proper preprocessing is crucial for model performance and stability.",
            "dependencies": [
                "Load User-Provided Data"
            ],
            "constraints": [
                "Only Open, High, Low, and Close (OHLC) columns are to be used as input features.",
                "Handle missing values using the forward fill method.",
                "Normalize the OHLC data to a range of [0, 1] using MinMaxScaler.",
                "Create input sequences using a sliding window of 60 past days of OHLC data to predict the 61st day's closing price."
            ]
        },
        {
            "task_name": "Split Dataset",
            "description": "This task divides the preprocessed data into distinct sets for training, validation, and testing. A chronological split is required to simulate a real-world scenario where the model is trained on past data and tested on future, unseen data. This separation is essential for unbiased model evaluation.",
            "dependencies": [
                "Preprocess Data"
            ],
            "constraints": [
                "The dataset must be split chronologically to preserve the time series order.",
                "Use an 80% for training, 10% for validation, and 10% for the test set split ratio."
            ]
        },
        {
            "task_name": "Build LSTM and Transformer Models",
            "description": "This task involves defining the architecture for two separate deep learning models: an LSTM and a Transformer. These models will be designed to process the sequential input data and predict the single next-day closing price. Building both allows for a comparative analysis of their performance on this specific forecasting problem.",
            "dependencies": [
                "Preprocess Data"
            ],
            "constraints": [
                "The selection of predictive models is strictly limited to LSTM and Transformer architectures.",
                "Both models must be designed to predict the closing price for only one day ahead.",
                "Implement the models using Python and either TensorFlow or PyTorch libraries."
            ]
        },
        {
            "task_name": "Train Models",
            "description": "In this task, both the LSTM and Transformer models are trained using the prepared training dataset. The training process involves iteratively feeding the data to the models to learn the underlying patterns. The validation set is used throughout training to monitor performance and prevent overfitting.",
            "dependencies": [
                "Split Dataset",
                "Build LSTM and Transformer Models"
            ],
            "constraints": [
                "Train both models on the 80% training set created in the data splitting task.",
                "Use the validation set after each epoch to monitor for overfitting."
            ]
        },
        {
            "task_name": "Evaluate Model Performance",
            "description": "This task assesses the predictive accuracy of the trained LSTM and Transformer models on the unseen test data. By calculating key performance metrics, this step provides a quantitative measure of how well each model is likely to perform on new, real-world data. The evaluation is critical for comparing the models and selecting the best performer.",
            "dependencies": [
                "Train Models",
                "Split Dataset"
            ],
            "constraints": [
                "Evaluate the models on the final 10% test set, which has not been seen during training.",
                "Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) as the performance metrics."
            ]
        },
        {
            "task_name": "Visualize Prediction Results",
            "description": "This task creates a visual comparison of the models' predictions against the actual stock prices from the test set. A time series graph provides an intuitive way to inspect the prediction quality, showing how closely the predicted values follow the actual price movements. This visualization aids in the qualitative assessment of model performance.",
            "dependencies": [
                "Evaluate Model Performance"
            ],
            "constraints": [
                "Generate a time series graph that overlays the predicted closing prices from each model on the actual closing prices from the test set."
            ]
        },
        {
            "task_name": "Visualize Training History",
            "description": "This task involves plotting the training and validation loss for each model over the training epochs. This visualization is crucial for diagnosing the training process, identifying issues like overfitting or underfitting, and understanding model convergence. The resulting plot helps justify the training setup and results.",
            "dependencies": [
                "Train Models"
            ],
            "constraints": [
                "Create a plot showing the training and validation loss function transition over epochs for both the LSTM and Transformer models.",
                "The generated plot must be saved as an image file."
            ]
        }
    ]
}