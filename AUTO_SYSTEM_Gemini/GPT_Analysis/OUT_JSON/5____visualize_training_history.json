"{\n  \"task_name\": \"visualize_training_history\",\n  \"module_responsibility\": \"This module is exclusively responsible for creating visual representations of the model training process. It generates plots that show the progression of training and validation loss over epochs for both the LSTM and Transformer models. Its scope is limited to data visualization and does not include model training, evaluation, or data processing.\",\n  \"model_role_and_purpose\": \"The purpose of this module is to provide a diagnostic tool to analyze the training phase of the deep learning models. By plotting training and validation loss curves on the same graph, it helps in identifying model behaviors such as overfitting (validation loss increases while training loss decreases), underfitting (both losses remain high), or ideal convergence. These visualizations are essential for validating the training strategy and for inclusion in final reports.\",\n  \"concrete_tasks\": [\n    {\n      \"task_id\": \"visualize_training_history_1\",\n      \"description\": \"Generates and saves a plot of the training and validation loss for a given model's training history.\",\n      \"interface\": \"plot_and_save_history(model_history, model_name, output_path)\",\n      \"inputs\": {\n        \"model_history\": {\n          \"type\": \"dict\",\n          \"description\": \"A dictionary-like object containing the training history. Must contain keys 'loss' and 'val_loss', each mapping to a list of floating-point numbers representing the loss at each epoch. This object is typically returned by the Keras `model.fit()` method.\"\n        },\n        \"model_name\": {\n          \"type\": \"str\",\n          \"description\": \"The name of the model (e.g., 'LSTM', 'Transformer') to be used in the plot title.\"\n        },\n        \"output_path\": {\n          \"type\": \"str\",\n          \"description\": \"The file path where the generated plot image will be saved (e.g., './plots/lstm_loss_history.png').\"\n        }\n      },\n      \"outputs\": {\n        \"status\": {\n          \"type\": \"str\",\n          \"description\": \"Returns the path of the saved image file upon successful creation.\"\n        }\n      }\n    }\n  ],\n  \"dependencies\": [\n    \"train_models\"\n  ],\n  \"constraints\": {\n    \"library_versions_and_configurations\": \"Use Python 3.8+. Required libraries: matplotlib (version 3.5.0 or newer). Plots must be saved in PNG format with a resolution of at least 300 DPI.\",\n    \"error_handling\": \"The module should handle exceptions gracefully. If 'model_history' is missing the required 'loss' or 'val_loss' keys, a KeyError should be raised. If the 'output_path' is invalid or not writable, an IOError or OSError should be caught and logged, preventing the pipeline from crashing.\",\n    \"input_formats_and_data_types\": \"The input 'model_history' must be a dictionary or a Keras History object with 'loss' and 'val_loss' keys, where values are lists of floats. 'model_name' and 'output_path' must be valid non-empty strings.\",\n    \"output_formats_and_data_types\": \"The module's primary output is the side effect of saving image files to the disk in PNG format. The function should return a string containing the path to the saved file.\",\n    \"specific_error_handling\": \"Any I/O errors during file saving must be logged with a timestamp and error message. Invalid input data should result in a ValueError or KeyError with a message indicating the exact problem (e.g., 'Missing val_loss key in history object').\"\n  },\n  \"code_skeleton\": \"import matplotlib.pyplot as plt\\nfrom typing import Dict, List\\n\\ndef plot_and_save_history(model_history: Dict[str, List[float]], model_name: str, output_path: str) -> str:\\n    \\\"\\\"\\\"\\n    Plots the training and validation loss from a model's training history and saves it to a file.\\n\\n    Args:\\n        model_history (Dict[str, List[float]]): A dictionary from Keras history, \\n                                                 containing 'loss' and 'val_loss' lists.\\n        model_name (str): The name of the model, used for the plot title (e.g., 'LSTM').\\n        output_path (str): The path to save the plot image file.\\n\\n    Returns:\\n        str: The path where the plot was saved.\\n\\n    Raises:\\n        KeyError: If 'loss' or 'val_loss' keys are not in model_history.\\n        IOError: If the file cannot be saved to the specified output_path.\\n    \\\"\\\"\\\"\\n    if 'loss' not in model_history or 'val_loss' not in model_history:\\n        raise KeyError(\\\"The 'model_history' dictionary must contain 'loss' and 'val_loss' keys.\\\")\\n\\n    plt.figure(figsize=(10, 6))\\n    plt.plot(model_history['loss'], label='Training Loss')\\n    plt.plot(model_history['val_loss'], label='Validation Loss')\\n    plt.title(f'{model_name} Model - Training & Validation Loss')\\n    plt.xlabel('Epoch')\\n    plt.ylabel('Loss')\\n    plt.legend()\\n    plt.grid(True)\\n    \\n    try:\\n        plt.savefig(output_path, dpi=300)\\n        plt.close()\\n    except IOError as e:\\n        print(f\\\"Error saving plot to {output_path}: {e}\\\")\\n        raise\\n\\n    return output_path\\n\",\n  \"documentation\": \"This module provides the `plot_and_save_history` function to visualize the training history of a deep learning model. It is designed to be called after the `train_models` module completes. It accepts a history object (containing loss and validation loss per epoch), a model name for titling, and a file path for saving the output. The module's responsibility is strictly visualization; it does not perform any data manipulation or model training. The output is two separate plot images, one for the LSTM model and one for the Transformer model, saved to the filesystem. This visual feedback is crucial for assessing model performance and diagnosing training issues like overfitting.\"\n}"